{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook using pre-defined Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mPyPl as mp\n",
    "import mPyPl as mp\n",
    "import mPyPl.utils.image as mpui\n",
    "from mpyplx import *\n",
    "from pipe import Pipe\n",
    "from moviepy.editor import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cv2\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mp.get_classes(data_dir)\n",
    "print(classes)\n",
    "classes = { 'attack' : 0, 'noshot': 1, 'shot': 2}\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = (\n",
    "   from_json(os.path.join(source_dir,'matches.json'))\n",
    " | mp.where(lambda x: 'Test' in x.keys() and int(x['Test'])>0)\n",
    " | mp.apply(['Id','Half'],'pattern',lambda x: \"{}_{}_\".format(x[0],x[1]))\n",
    " | mp.select_field('pattern')\n",
    " | mp.as_list)\n",
    "\n",
    "data = (\n",
    "   mp.get_datastream(data_dir,classes=classes,ext=\".resized.mp4\") \n",
    " | datasplit_by_pattern(test_pattern=test_names)\n",
    " | mp.sapply( 'class_id', lambda x: 2-(1 if x==0 else x) )\n",
    " | stratify_sample_tt()\n",
    " | mp.apply(['class_id','split'],'descr',lambda x: \"{}-{}\".format(x[0],x[1]))\n",
    " | summarize('descr')\n",
    " | mp.as_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data | mp.take(5) | mp.as_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printf(x,y):\n",
    "    print(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "**NB:** the following cell will take a long time to run, as it pre-computes all audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_sampling = 5.0/126.0*audio_rate\n",
    "data_audio = (data\n",
    " | mp.silly_progress(elements=10000)\n",
    " | load_moviepy_video()\n",
    " | mp.apply('video','audio',lambda x: audioFeatureExtraction.stFeatureExtraction(audioBasicIO.stereo2mono(x.audio.to_soundarray()),audio_rate, 2.0*snd_sampling,snd_sampling)[0])\n",
    " | close_moviepy_video()\n",
    " | mp.inspect()\n",
    " | mp.as_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save audio features for future use\n",
    "pickle.dump(data_audio, open('sound_data_set.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_audio = pickle.load(open('x:/data_etc/sound_data_set.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes = data_audio | mp.select_field('audio') | mp.select(lambda x: np.max(x,axis=1)) | mp.as_npy\n",
    "features_max = list(np.max(maxes,axis=0))\n",
    "mins = data_audio | mp.select_field('audio') | mp.select(lambda x: np.min(x,axis=1)) | mp.as_npy\n",
    "features_min = [0.0 if 0<x<0.01 else x for x in np.min(mins,axis=0)]\n",
    "audio_minimax = list(zip(features_min,features_max))\n",
    "print(audio_minimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save audio minimax values for inferencing\n",
    "json.dump(audio_minimax, open('audio_minimax.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_minimax = np.array(audio_minimax)\n",
    "mn = audio_minimax[:,0]\n",
    "wd = audio_minimax[:,1]-audio_minimax[:,0]\n",
    "\n",
    "def norm(x):\n",
    "    return ((x.transpose()-mn)/wd).transpose()\n",
    "\n",
    "trainstream, valstream = (data_audio \n",
    " | mp.apply('audio','audiox',lambda x: np.expand_dims(norm(x),axis=2))\n",
    " | mp.inspect \n",
    " | mp.make_train_test_split)\n",
    "                          \n",
    "no_train = data_audio | mp.filter('split',lambda x: x==mp.SplitType.Train) | mp.count\n",
    "no_test = data_audio | mp.filter('split',lambda x: x==mp.SplitType.Test) | mp.count\n",
    "print(\"Train={}, Test={}\".format(no_train,no_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (1, 3), input_shape=(34, 126, 1), data_format='channels_last',activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(AveragePooling2D((1, 2)))\n",
    "model.add(Conv2D(16, (1, 3) ,activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(AveragePooling2D((1, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valstream = valstream | mp.as_list\n",
    "\n",
    "history = model.fit_generator(\n",
    "      trainstream | mp.infshuffle |  mp.as_batch('audiox', 'class_id', batchsize=batchsize),\n",
    "      steps_per_epoch=no_train // batchsize,\n",
    "      validation_data= valstream | mp.infshuffle | mp.as_batch('audiox', 'class_id', batchsize=batchsize),\n",
    "      validation_steps = no_test // batchsize,\n",
    "      epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"x:/models/audio126.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}