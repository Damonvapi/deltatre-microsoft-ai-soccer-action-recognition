{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "import mPyPl as mp\n",
    "from mPyPl.utils.flowutils import *\n",
    "from mpyplx import *\n",
    "from pipe import Pipe\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "from moviepy.editor import *\n",
    "import pickle\n",
    "import functools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "test_names = (\n",
    "   from_json(os.path.join(source_dir,'matches.json'))\n",
    "   | mp.where(lambda x: 'Test' in x.keys() and int(x['Test'])>0)\n",
    "   | mp.apply(['Id','Half'],'pattern',lambda x: \"{}_{}_\".format(x[0],x[1]))\n",
    "   | mp.select_field('pattern')\n",
    "   | mp.as_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = (\n",
    "    mp.get_datastream(data_dir, ext=\".fflow.pickle\", classes={'noshot' : 0, 'shots': 1})\n",
    "    | datasplit_by_pattern(test_pattern=test_names)\n",
    "    | stratify_sample_tt()\n",
    "    | mp.apply(['class_id','split'],'descr',lambda x: \"{}-{}\".format(x[0],x[1]))\n",
    "    | summarize('descr')\n",
    "    | mp.as_list\n",
    ")\n",
    "\n",
    "train, test = (\n",
    "    stream\n",
    "    | mp.apply('filename', 'raw', lambda x: pickle.load(open(x, 'rb')), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('raw', 'gradients', calc_gradients, eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('gradients', 'polar', lambda x: to_polar(x), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('polar', 'channel1', lambda x: np.concatenate([y[0] for y in x]), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('polar', 'channel2', lambda x: np.concatenate([y[1] for y in x]), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.make_train_test_split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train | mp.as_list\n",
    "\n",
    "ch1 = stream  | mp.select_field('channel1') | mp.as_list\n",
    "ch1_flatten = np.concatenate(ch1)\n",
    "\n",
    "ch2 = stream  | mp.select_field('channel2') | mp.as_list\n",
    "ch2_flatten = np.concatenate(ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(ch1_flatten, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(ch2_flatten, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpticalFlow Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_changes = pickle.load(open('scene.changes.pkl', 'rb'))\n",
    "scene_changes = list(scene_changes[40].keys())\n",
    "scene_changes = [ fn.replace('.resized.mp4', '.fflow.pickle') for fn in scene_changes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinaflow_shape = (25, 50, 2)\n",
    "\n",
    "hist_params = [\n",
    "    dict(\n",
    "        bins=retinaflow_shape[1],\n",
    "        lower=0,\n",
    "        upper=150,\n",
    "        maxv=150\n",
    "    ),\n",
    "    dict(\n",
    "        bins=retinaflow_shape[1],\n",
    "        lower=0,\n",
    "        upper=6.29,\n",
    "        maxv=6.29 \n",
    "    ),\n",
    "]\n",
    "\n",
    "stream = (\n",
    "    mp.get_datastream(data_dir, ext=\".fflow.pickle\", classes={'noshot' : 0, 'shots': 1})\n",
    "    | mp.filter('filename', lambda x: not x in scene_changes) \n",
    "    | datasplit_by_pattern(test_pattern=test_names)\n",
    "    | stratify_sample_tt()\n",
    "    | mp.apply(['class_id','split'],'descr',lambda x: \"{}-{}\".format(x[0],x[1]))\n",
    "    | summarize('descr')\n",
    "    | mp.as_list\n",
    ")\n",
    "\n",
    "train, test = (\n",
    "    stream\n",
    "    | mp.apply('filename', 'raw', lambda x: pickle.load(open(x, 'rb')), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('raw', 'gradients', calc_gradients, eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('gradients', 'polar', lambda x: to_polar(x), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('polar', 'histograms', lambda x: video_to_hist(x, hist_params), eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.apply('histograms', 'fflows', functools.partial(zero_pad,shape=retinaflow_shape), \n",
    "               eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    "    | mp.make_train_test_split()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_train = stream | mp.filter('split',lambda x: x==mp.SplitType.Train) | mp.count\n",
    "no_test = stream | mp.filter('split',lambda x: x==mp.SplitType.Test) | mp.count\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 0.001\n",
    "V = \"v1\"\n",
    "MODEL_CHECKPOINT = \"models/unet_ch_\" + V + \".h5\"\n",
    "MODEL_PATH = MODEL_CHECKPOINT.replace(\"_ch_\", \"_model_\")\n",
    "HISTORY_PATH = MODEL_PATH.replace(\".h5\", \"_history.pkl\")\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    MODEL_CHECKPOINT, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "callback_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0, \n",
    "    patience=7, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.5,\n",
    "                              patience=4, cooldown=4, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "retinaflow_shape = (25, 50, 2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5,3), input_shape=retinaflow_shape))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "        train | mp.infshuffle |  mp.as_batch('fflows', 'class_id', batchsize=BATCH_SIZE),\n",
    "        steps_per_epoch = no_train // BATCH_SIZE,\n",
    "        validation_data = test | mp.infshuffle | mp.as_batch('fflows', 'class_id', batchsize=BATCH_SIZE),\n",
    "        validation_steps = no_test // BATCH_SIZE,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        callbacks=[callback_checkpoint, callback_stopping, reduce_lr]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}