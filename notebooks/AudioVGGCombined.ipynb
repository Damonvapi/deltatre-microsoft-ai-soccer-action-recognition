{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook using pre-defined Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mPyPl as mp\n",
    "import mPyPl as mp\n",
    "import mPyPl.utils.image as mpui\n",
    "from mpyplx import *\n",
    "from pipe import Pipe\n",
    "from moviepy.editor import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mp.get_classes(data_dir)\n",
    "print(classes)\n",
    "classes = { 'noshot' : 1, 'shot': 2}\n",
    "print(classes)\n",
    "\n",
    "stream = mp.get_datastream(data_dir,classes=classes,ext=\".resized.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream | mp.take(5) | mp.as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mp.get_classes(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = (\n",
    "   from_json(os.path.join(source_dir,'matches.json'))\n",
    " | mp.where(lambda x: 'Test' in x.keys() and int(x['Test'])>0)\n",
    " | mp.apply(['Id','Half'],'pattern',lambda x: \"{}_{}_\".format(x[0],x[1]))\n",
    " | mp.select_field('pattern')\n",
    " | mp.as_list)\n",
    "\n",
    "data = (\n",
    "   mp.get_datastream(data_dir,classes=classes,ext=\".resized.mp4\") \n",
    " | datasplit_by_pattern(test_pattern=test_names)\n",
    " | mp.sapply( 'class_id', lambda x: 2-(1 if x==0 else x) )\n",
    " | stratify_sample_tt()\n",
    " | mp.apply(['class_id','split'],'descr',lambda x: \"{}-{}\".format(x[0],x[1]))\n",
    " | summarize('descr')\n",
    " | mp.as_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data | mp.take(5) | mp.as_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printf(x,y):\n",
    "    print(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data\n",
    " | mp.apply('filename','audio',lambda x: np.load(x.replace('.resized.mp4','.audiofeatures.npy')),eval_strategy=mp.EvalStrategies.OnDemand)\n",
    " | mp.apply('audio','audio_third',lambda x: x.reshape( (34,200,1) ),eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    " | mp.apply('filename','vgg',lambda x: np.load(x.replace('.resized.mp4','.vgg.npy')),eval_strategy=mp.EvalStrategies.OnDemand)\n",
    " | mp.apply('vgg','vggflat',lambda x: np.reshape(x,(no_frames,-1,1)),eval_strategy=mp.EvalStrategies.LazyMemoized)\n",
    " | mp.as_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][\"audio_third\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstream, valstream = data | mp.make_train_test_split\n",
    "no_train = data | mp.filter('split',lambda x: x==mp.SplitType.Train) | mp.count\n",
    "no_test = data | mp.filter('split',lambda x: x==mp.SplitType.Test) | mp.count\n",
    "print(\"Train={}, Test={}\".format(no_train,no_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio CNN\n",
    "batchsize=32\n",
    "\n",
    "model_audio = Sequential()\n",
    "model_audio.add(Conv2D(32, (1, 3), input_shape=(34, 200, 1), data_format='channels_last',activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model_audio.add(AveragePooling2D((1, 2)))\n",
    "model_audio.add(Conv2D(16, (1, 3) ,activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model_audio.add(AveragePooling2D((1, 2)))\n",
    "model_audio.add(Flatten())\n",
    "model_audio.add(Dropout(0.5))\n",
    "model_audio.add(Dense(10,activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model_audio.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_frames=126\n",
    "\n",
    "model_vgg = Sequential()\n",
    "model_vgg.add(AveragePooling2D((12,12),input_shape=(no_frames, 16384, 1)))\n",
    "model_vgg.add(Conv2D(8, (3, 3), data_format='channels_last',activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model_vgg.add(AveragePooling2D((2, 2)))\n",
    "model_vgg.add(Conv2D(16, (3, 3) ,activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "model_vgg.add(AveragePooling2D((2, 2)))\n",
    "model_vgg.add(Flatten())\n",
    "model_vgg.add(Dropout(0.5))\n",
    "model_vgg.add(Dense(10,activation='relu',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "input1 = Input(shape=(no_frames, 16384, 1))\n",
    "input2 = Input(shape=(34, 200, 1))\n",
    "concat = concatenate([model_vgg(input1),model_audio(input2)])\n",
    "output = Dense(1, activation='sigmoid',kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.01))(concat)\n",
    "                                                                                                        \n",
    "model = Model(input=[input1,input2],output=output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "checkpoint =  keras.callbacks.ModelCheckpoint(filepath, \n",
    "                          monitor='val_loss', \n",
    "                          verbose=0, \n",
    "                          save_best_only=True, \n",
    "                          save_weights_only=False, \n",
    "                          mode='auto', \n",
    "                          period=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.0001,\n",
    "                              patience=6,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valstream = valstream | mp.as_list\n",
    "\n",
    "history = model.fit_generator(\n",
    "      trainstream | mp.infshuffle |  mp.as_batch( ['vggflat','audio_third'], 'class_id', batchsize=batchsize),\n",
    "      steps_per_epoch=no_train // batchsize,\n",
    "      validation_data= valstream | mp.infshuffle | mp.as_batch(['vggflat','audio_third'], 'class_id', batchsize=batchsize),\n",
    "      validation_steps = no_test // batchsize,\n",
    "      epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"audio-features-300-34-1.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.vgg.audio.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = valstream  | mp.select_field(\"vggflat\") | mp.as_npy\n",
    "\n",
    "print(test_examples.shape)\n",
    "\n",
    "preds = model.predict(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valstream | mp.fapply(\"pred_acc\", lambda x: getc ) | execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}